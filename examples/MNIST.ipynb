{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains a working example of running stochastic gradient descent on MNIST using dreaml. It performs PCA and genereates random kitchen sink features while running mini-batched stochastic gradient descent. You can adjust the hyperparameters (i.e. step size) or generate more features and observe the resulting performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named dreaml",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ec6306561b8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdreaml\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdreaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdreaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named dreaml"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import cPickle, gzip\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import dreaml as dm\n",
    "from dreaml.server import start\n",
    "from dreaml.loss import Softmax\n",
    "import dreaml.transformations as trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data from files\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "n_train=1000\n",
    "n_test=100\n",
    "X_train = train_set[0][0:n_train,:]\n",
    "y_train = train_set[1][0:n_train,None]\n",
    "X_test = valid_set[0][0:n_train,:]\n",
    "y_test = valid_set[1][0:n_train,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialize the dataframe and start the web frontend for visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = dm.DataFrame()\n",
    "start(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we load the data into the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"data/train/\", \"input/raw/\"] = dm.DataFrame.from_matrix(X_train)\n",
    "df[\"data/train/\", \"input/label/\"] = dm.DataFrame.from_matrix(y_train)\n",
    "df[\"data/test/\", \"input/raw/\"] = dm.DataFrame.from_matrix(X_test)\n",
    "df[\"data/test/\", \"input/label/\"] = dm.DataFrame.from_matrix(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run PCA on the input. These are placed within the features folder. Note that the PCA transformation creates the PCA basis vectors as part of the subroutine. These are stored in an automatically generated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"data/\", \"features/pca/\"] = trans.PCA(df[\"data/train/\", \"input/raw/\"], \n",
    "                                         df[\"data/\",\"input/raw/\"],\n",
    "                                         num_bases=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the PCA features, we also generate an initial set of 1000 kitchen sink features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"data/\", \"features/ks1/\"] = trans.KitchenSinks(df[\"data/\",\"features/pca/\"],\n",
    "                                                  num_features=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we start the stochastic gradient descent process using Softmax loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"weights/\", \"features/\"] = trans.SGD(Softmax,\n",
    "                                      np.zeros((50,1000)),\n",
    "                                      df[\"data/train/\", \"features/\"],\n",
    "                                      df[\"data/train/\",\"input/label/\"],\n",
    "                                      batch_size=50,\n",
    "                                      reg=0.01,\n",
    "                                      step_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute some metrics on each datapoint to evaluate the progress of our model. In this case, softmax loss and multi-classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"data/\",\"metrics/\"] = trans.Metrics([Softmax.f_vec, Softmax.err],\n",
    "                                       df[\"weights/\", \"features/\"],\n",
    "                                       df[\"data/\", \"features/\"],\n",
    "                                       df[\"data/\", \"input/label/\"],\n",
    "                                       reg=0.01,\n",
    "                                       metrics_names=[\"SoftmaxLoss\",\n",
    "                                                      \"MulticlassError\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can plot a sequence of evaluations of arbitrary functions f that return a pair of lists (ys,xs) of numbers to plots. In this case, we compute the average softmax loss of all the training examples over the number of iterations, and the [trainerr,testerr] also over the number of iterations. These plots show up on the web frontend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def softmax_average():\n",
    "  metrics = df[\"data/\",\"metrics/\"].get_matrix()\n",
    "  n = df[\"data/train/\",\"metrics/\"].shape()[0]\n",
    "  niters = df[\"weights/\", \"features/\"].T().niters\n",
    "  return ([np.mean(metrics[0:n,0])],[niters])\n",
    "\n",
    "def traintest_average():\n",
    "  metrics = df[\"data/\",\"metrics/\"].get_matrix()\n",
    "  n = df[\"data/train/\",\"metrics/\"].shape()[0]\n",
    "  niters = df[\"weights/\", \"features/\"].T().niters\n",
    "  return ([np.mean(metrics[0:n,1]),np.mean(metrics[n+1:,1])],[niters,niters])\n",
    "\n",
    "df[\"plot/\",\"loss/\"] = dm.Plotter(softmax_average,\n",
    "                                 \"objective loss\",\n",
    "                                 legend=[\"softmax\"])\n",
    "\n",
    "df[\"plot/\",\"err/\"] = dm.Plotter(traintest_average,\n",
    "                                \"train and test err\",\n",
    "                                legend=[\"train\",\"test\"],\n",
    "                                colors=[\"blue\",\"green\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our plots set up, we can make changes to the model and see how dreaml reactively implements these changes in real-time!\n",
    "\n",
    "Example 1: You might have noticed that the training and testing error is all over the place. The following code retrieves the SGD transformation and changes the value of the step size being taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"weights/\", \"features/\"].T().step_size = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: we can continue to generate more random kitchen sink features. Try it and see how it affects the model's performance. Note that all existing transformations see the change and restart accordingly, if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"data/\", \"features/ks2/\"] = trans.KitchenSinks(df[\"data/\",\"features/pca/\"],\n",
    "                                                  num_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"data/\", \"features/ks3/\"] = trans.KitchenSinks(df[\"data/\",\"features/pca/\"],\n",
    "                                                  num_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"data/\", \"features/ks4/\"] = trans.KitchenSinks(df[\"data/\",\"features/pca/\"],\n",
    "                                                  num_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
